{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adver_data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = adver_data['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "means, stds = np.mean(X, axis=0), np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X-means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  9.69852266e-01  9.81522472e-01  1.77894547e+00]\n",
      " [ 1.00000000e+00 -1.19737623e+00  1.08280781e+00  6.69578760e-01]\n",
      " [ 1.00000000e+00 -1.51615499e+00  1.52846331e+00  1.78354865e+00]\n",
      " [ 1.00000000e+00  5.20496822e-02  1.21785493e+00  1.28640506e+00]\n",
      " [ 1.00000000e+00  3.94182198e-01 -8.41613655e-01  1.28180188e+00]\n",
      " [ 1.00000000e+00 -1.61540845e+00  1.73103399e+00  2.04592999e+00]\n",
      " [ 1.00000000e+00 -1.04557682e+00  6.43904671e-01 -3.24708413e-01]\n",
      " [ 1.00000000e+00 -3.13436589e-01 -2.47406325e-01 -8.72486994e-01]\n",
      " [ 1.00000000e+00 -1.61657614e+00 -1.42906863e+00 -1.36042422e+00]\n",
      " [ 1.00000000e+00  6.16042873e-01 -1.39530685e+00 -4.30581584e-01]\n",
      " [ 1.00000000e+00 -9.45155670e-01 -1.17923146e+00 -2.92486143e-01]\n",
      " [ 1.00000000e+00  7.90028350e-01  4.96973404e-02 -1.22232878e+00]\n",
      " [ 1.00000000e+00 -1.43908760e+00  7.99208859e-01  1.62704048e+00]\n",
      " [ 1.00000000e+00 -5.78501712e-01 -1.05768905e+00 -1.07502697e+00]\n",
      " [ 1.00000000e+00  6.66253447e-01  6.50657027e-01  7.11007392e-01]\n",
      " [ 1.00000000e+00  5.64664612e-01  1.65000572e+00  1.02862691e+00]\n",
      " [ 1.00000000e+00 -9.25304978e-01  9.00494200e-01  3.84117072e+00]\n",
      " [ 1.00000000e+00  1.56887609e+00  1.10306488e+00  1.16211917e+00]\n",
      " [ 1.00000000e+00 -9.08957349e-01 -1.86635121e-01 -5.64073843e-01]\n",
      " [ 1.00000000e+00  3.00679600e-03  4.29449843e-02 -5.27248393e-01]\n",
      " [ 1.00000000e+00  8.33232798e-01  2.99534513e-01  1.05164281e+00]\n",
      " [ 1.00000000e+00  1.05509347e+00 -1.22649795e+00 -3.24708413e-01]\n",
      " [ 1.00000000e+00 -1.56286250e+00 -4.97243498e-01  8.76721921e-01]\n",
      " [ 1.00000000e+00  9.48833887e-01 -4.29719938e-01 -2.00422516e-01]\n",
      " [ 1.00000000e+00 -9.89527805e-01 -7.20071247e-01 -5.64073843e-01]\n",
      " [ 1.00000000e+00  1.35285385e+00 -1.33453565e+00 -5.08835667e-01]\n",
      " [ 1.00000000e+00 -4.83714657e-02  4.07572210e-01 -8.26455181e-01]\n",
      " [ 1.00000000e+00  1.08662104e+00 -4.43224650e-01 -3.52327501e-01]\n",
      " [ 1.00000000e+00  1.18820988e+00  2.59020377e-01 -3.52327501e-01]\n",
      " [ 1.00000000e+00 -8.92609721e-01 -4.90491142e-01  4.71641962e-01]\n",
      " [ 1.00000000e+00  1.70316018e+00  3.40048650e-01  5.82118314e-01]\n",
      " [ 1.00000000e+00 -3.98677796e-01 -3.95958157e-01  3.70371972e-01]\n",
      " [ 1.00000000e+00 -5.82004775e-01 -1.46958277e+00 -2.55016247e-02]\n",
      " [ 1.00000000e+00  1.38438142e+00 -2.20396901e-01 -1.39264649e+00]\n",
      " [ 1.00000000e+00 -5.99520091e-01 -1.47633512e+00 -1.06582061e+00]\n",
      " [ 1.00000000e+00  1.67747105e+00 -1.29402151e+00 -1.01518562e+00]\n",
      " [ 1.00000000e+00  1.39956136e+00  1.38666383e+00 -1.17629696e+00]\n",
      " [ 1.00000000e+00 -8.44734522e-01  1.76479577e+00  6.97197848e-01]\n",
      " [ 1.00000000e+00 -1.21372386e+00  2.32010953e-01  2.09260624e-01]\n",
      " [ 1.00000000e+00  9.45330823e-01  9.74770116e-01  6.65620024e-02]\n",
      " [ 1.00000000e+00  6.47570443e-01 -6.50927121e-02  4.81492770e-02]\n",
      " [ 1.00000000e+00  3.49810063e-01  6.84418807e-01  3.74975153e-01]\n",
      " [ 1.00000000e+00  1.71133400e+00  2.99534513e-01 -1.32359877e+00]\n",
      " [ 1.00000000e+00  6.98948705e-01 -1.00367020e+00 -1.91216154e-01]\n",
      " [ 1.00000000e+00 -1.42390765e+00  1.64487393e-01  5.86721496e-01]\n",
      " [ 1.00000000e+00  3.27623995e-01 -5.15880000e-02  4.35460956e-02]\n",
      " [ 1.00000000e+00 -6.69581357e-01 -9.02384859e-01  2.36879713e-01]\n",
      " [ 1.00000000e+00  1.08428567e+00  1.23135965e+00 -5.54867481e-01]\n",
      " [ 1.00000000e+00  9.35989321e-01 -5.03995854e-01  8.90531465e-01]\n",
      " [ 1.00000000e+00 -9.35814168e-01 -7.80842451e-01  2.87514708e-01]\n",
      " [ 1.00000000e+00  6.16042873e-01 -1.36154507e+00  1.86244718e-01]\n",
      " [ 1.00000000e+00 -5.44638766e-01 -9.22641928e-01 -1.24074150e+00]\n",
      " [ 1.00000000e+00  8.09879042e-01  1.24486436e+00  4.16403786e-01]\n",
      " [ 1.00000000e+00  4.15200577e-01  1.54872038e+00  1.29561142e+00]\n",
      " [ 1.00000000e+00  1.35051848e+00  3.73810430e-01 -6.74550196e-01]\n",
      " [ 1.00000000e+00  6.05533683e-01  1.76479577e+00  1.35545278e+00]\n",
      " [ 1.00000000e+00 -1.63175608e+00  3.26543937e-01  4.99261050e-01]\n",
      " [ 1.00000000e+00 -1.26606546e-01 -2.74415749e-01 -6.42327927e-01]\n",
      " [ 1.00000000e+00  7.44488528e-01  1.77830048e+00  3.28943340e-01]\n",
      " [ 1.00000000e+00  7.43320840e-01  4.21076922e-01 -9.78360166e-01]\n",
      " [ 1.00000000e+00 -1.09228433e+00 -1.43582099e+00 -4.21375221e-01]\n",
      " [ 1.00000000e+00  1.33417085e+00  1.31238792e+00  1.11148417e+00]\n",
      " [ 1.00000000e+00  1.07727954e+00 -5.24252922e-01 -1.49787521e-01]\n",
      " [ 1.00000000e+00 -5.17781948e-01  4.27829278e-01 -1.01978880e+00]\n",
      " [ 1.00000000e+00 -1.86158622e-01  1.31914027e+00 -7.61366196e-02]\n",
      " [ 1.00000000e+00 -9.11292725e-01 -9.42898996e-01 -1.36502740e+00]\n",
      " [ 1.00000000e+00 -1.34917564e+00  9.02114765e-02 -1.30518604e+00]\n",
      " [ 1.00000000e+00 -9.04082253e-02 -5.91776482e-01 -9.36931533e-01]\n",
      " [ 1.00000000e+00  1.05509347e+00  2.86029801e-01 -9.00106083e-01]\n",
      " [ 1.00000000e+00  8.14549794e-01  1.39341619e+00 -1.54390703e-01]\n",
      " [ 1.00000000e+00  6.07869059e-01  4.95352838e-01  3.74975153e-01]\n",
      " [ 1.00000000e+00 -4.34876116e-01 -6.05281194e-01  5.27524584e-02]\n",
      " [ 1.00000000e+00 -1.40405696e+00  6.57409383e-01 -5.18042030e-01]\n",
      " [ 1.00000000e+00 -2.06009314e-01 -1.18598381e+00  3.43397329e-02]\n",
      " [ 1.00000000e+00  7.74848409e-01  9.02114765e-02 -8.03439274e-01]\n",
      " [ 1.00000000e+00 -1.51965805e+00  1.37991148e+00  2.70878810e+00]\n",
      " [ 1.00000000e+00 -1.39588315e+00 -1.46283041e+00 -4.53597491e-01]\n",
      " [ 1.00000000e+00 -3.09933525e-01  3.53553362e-01 -7.52804279e-01]\n",
      " [ 1.00000000e+00 -1.65394214e+00  4.48086346e-01 -9.73756984e-01]\n",
      " [ 1.00000000e+00 -3.62479475e-01 -1.05093669e+00 -3.43121138e-01]\n",
      " [ 1.00000000e+00 -8.24883830e-01  2.32010953e-01 -3.79946589e-01]\n",
      " [ 1.00000000e+00  1.08311798e+00 -1.29402151e+00  2.92117889e-01]\n",
      " [ 1.00000000e+00 -8.37728396e-01 -2.00139833e-01  8.95779092e-02]\n",
      " [ 1.00000000e+00 -9.18298852e-01  1.43393033e+00  2.32276531e-01]\n",
      " [ 1.00000000e+00  7.76016097e-01  1.33264499e+00  1.49419267e-01]\n",
      " [ 1.00000000e+00  5.38975481e-01 -3.28434597e-01  1.61783412e+00]\n",
      " [ 1.00000000e+00 -8.26051518e-01  2.86029801e-01 -6.69947015e-01]\n",
      " [ 1.00000000e+00 -4.24366926e-01  1.17058844e+00  1.50275459e+00]\n",
      " [ 1.00000000e+00 -6.85928986e-01  1.50982681e-01  1.97227908e+00]\n",
      " [ 1.00000000e+00 -4.34876116e-01  1.65675807e+00  9.59579186e-01]\n",
      " [ 1.00000000e+00 -1.48792614e-01 -1.24000266e+00 -9.78360166e-01]\n",
      " [ 1.00000000e+00 -1.38303858e+00 -1.46958277e+00  1.12593816e-01]\n",
      " [ 1.00000000e+00  8.25058983e-01  6.91171163e-01  1.30942097e+00]\n",
      " [ 1.00000000e+00  1.21273132e+00  8.93741844e-01  1.92164409e+00]\n",
      " [ 1.00000000e+00 -4.62900623e-01 -6.25538262e-01 -9.04709264e-01]\n",
      " [ 1.00000000e+00  1.89836839e-01  5.62876398e-01  1.02862691e+00]\n",
      " [ 1.00000000e+00  5.90353742e-01 -1.33453565e+00 -1.13486833e+00]\n",
      " [ 1.00000000e+00  4.42057396e-01 -1.52873340e-01 -3.93756133e-01]\n",
      " [ 1.00000000e+00  1.66579418e+00  1.28537849e+00  9.50372823e-01]\n",
      " [ 1.00000000e+00 -1.38283424e-01  1.24486436e+00  7.06404211e-01]\n",
      " [ 1.00000000e+00  8.79940308e-01 -1.28051680e+00  8.85928284e-01]\n",
      " [ 1.00000000e+00  1.74402926e+00  8.80237132e-01  3.23815396e+00]\n",
      " [ 1.00000000e+00  1.55486384e+00 -8.88880147e-01 -4.21375221e-01]\n",
      " [ 1.00000000e+00  4.77088029e-01 -4.09462869e-01 -5.82486569e-01]\n",
      " [ 1.00000000e+00  1.06443498e+00  7.45190011e-01 -1.16248742e+00]\n",
      " [ 1.00000000e+00 -1.06755854e-01  1.56222509e+00  1.30942097e+00]\n",
      " [ 1.00000000e+00 -1.42507534e+00 -8.28108943e-01 -3.93111688e-02]\n",
      " [ 1.00000000e+00 -6.61407543e-01 -1.55061104e+00 -3.38517957e-01]\n",
      " [ 1.00000000e+00 -1.56403019e+00 -1.54385868e+00 -2.28041604e-01]\n",
      " [ 1.00000000e+00  1.26527727e+00  2.45515665e-01 -1.15328106e+00]\n",
      " [ 1.00000000e+00  9.19641692e-01 -1.01717491e+00  1.19434143e+00]\n",
      " [ 1.00000000e+00  1.10530405e+00  9.95027184e-01 -3.38517957e-01]\n",
      " [ 1.00000000e+00  3.34630122e-01 -5.31005278e-01 -1.29597968e+00]\n",
      " [ 1.00000000e+00  7.30476274e-01 -1.79882765e-01 -9.13915627e-01]\n",
      " [ 1.00000000e+00 -8.03865450e-01  1.58923451e+00  1.81641536e-01]\n",
      " [ 1.00000000e+00 -8.40063771e-01  7.92456503e-01  1.01942054e+00]\n",
      " [ 1.00000000e+00 -9.15759131e-02 -6.05281194e-01 -2.28041604e-01]\n",
      " [ 1.00000000e+00 -8.24883830e-01 -1.51684926e+00 -7.25185191e-01]\n",
      " [ 1.00000000e+00 -2.49213762e-01  9.20751268e-01  2.23926360e+00]\n",
      " [ 1.00000000e+00 -1.49046586e+00 -4.90491142e-01 -3.79946589e-01]\n",
      " [ 1.00000000e+00 -6.70544700e-02  2.38763309e-01  7.20213755e-01]\n",
      " [ 1.00000000e+00 -1.49747198e+00 -1.05606848e-01  9.13547372e-01]\n",
      " [ 1.00000000e+00  8.98623313e-01 -1.40881156e+00 -6.88359740e-01]\n",
      " [ 1.00000000e+00 -2.79573643e-01  7.65447079e-01 -8.35661544e-01]\n",
      " [ 1.00000000e+00  9.62846140e-01  6.10142891e-01  2.00910454e+00]\n",
      " [ 1.00000000e+00 -6.98773552e-01 -7.74090095e-01 -2.14232060e-01]\n",
      " [ 1.00000000e+00 -1.62591764e+00  1.05579839e+00  9.22753735e-01]\n",
      " [ 1.00000000e+00 -7.80511695e-01 -1.57086811e+00 -9.82963347e-01]\n",
      " [ 1.00000000e+00  8.55418865e-01  1.73778635e+00 -1.25915423e+00]\n",
      " [ 1.00000000e+00 -1.02105537e+00 -7.60585383e-01  5.77515133e-01]\n",
      " [ 1.00000000e+00 -1.70882347e+00  1.10306488e+00 -1.00597925e+00]\n",
      " [ 1.00000000e+00  1.37971067e+00 -1.37504978e+00  5.72911952e-01]\n",
      " [ 1.00000000e+00 -1.61891151e+00  2.65772733e-01 -1.30978922e+00]\n",
      " [ 1.00000000e+00  8.49580427e-01  6.91171163e-01  6.69578760e-01]\n",
      " [ 1.00000000e+00 -1.28612050e+00  1.03554132e+00  1.61323094e+00]\n",
      " [ 1.00000000e+00 -1.15300409e+00  1.60273923e+00 -1.01518562e+00]\n",
      " [ 1.00000000e+00 -1.41806922e+00  1.06255074e+00 -9.78360166e-01]\n",
      " [ 1.00000000e+00  1.47896413e+00  3.80562786e-01  1.34164324e+00]\n",
      " [ 1.00000000e+00 -1.21489154e+00  1.77992105e-01 -4.62803854e-01]\n",
      " [ 1.00000000e+00  4.42057396e-01  1.39341619e+00 -1.32820195e+00]\n",
      " [ 1.00000000e+00 -8.59914463e-01 -4.22967582e-01 -8.12645637e-01]\n",
      " [ 1.00000000e+00  5.44813920e-01  8.19465927e-01  2.07354907e+00]\n",
      " [ 1.00000000e+00  8.57754241e-01  6.70914095e-01  3.38149702e-01]\n",
      " [ 1.00000000e+00 -4.95595880e-01 -1.18598381e+00  1.77038355e-01]\n",
      " [ 1.00000000e+00 -5.93681653e-01 -5.71519414e-01  3.84181516e-01]\n",
      " [ 1.00000000e+00 -7.87313476e-02 -1.44257334e+00 -9.92169710e-01]\n",
      " [ 1.00000000e+00  1.08662104e+00 -1.07794612e+00 -1.00597925e+00]\n",
      " [ 1.00000000e+00  1.12281936e+00  1.73778635e+00  6.32753309e-01]\n",
      " [ 1.00000000e+00 -1.27327593e+00  1.15033137e+00 -8.58677450e-01]\n",
      " [ 1.00000000e+00 -1.19504085e+00  1.71239749e-01 -4.58200672e-01]\n",
      " [ 1.00000000e+00  1.56070228e+00 -6.32290618e-01  2.96721070e-01]\n",
      " [ 1.00000000e+00 -3.04095087e-01 -1.00367020e+00  8.35293289e-01]\n",
      " [ 1.00000000e+00  5.90353742e-01  2.43084817e-03 -7.52804279e-01]\n",
      " [ 1.00000000e+00  2.83251860e-01  1.10981724e+00  3.28943340e-01]\n",
      " [ 1.00000000e+00  4.75920341e-01 -1.46120984e-01 -9.69153803e-01]\n",
      " [ 1.00000000e+00 -1.66912209e+00 -7.87594807e-01 -1.14407469e+00]\n",
      " [ 1.00000000e+00 -6.20538471e-01  1.36640677e+00  9.18150553e-01]\n",
      " [ 1.00000000e+00  3.21989902e-02 -1.48308748e+00 -2.87882962e-01]\n",
      " [ 1.00000000e+00 -1.58037782e+00  9.20751268e-01  6.74181942e-01]\n",
      " [ 1.00000000e+00 -1.79152496e-01 -3.28434597e-01  1.86244718e-01]\n",
      " [ 1.00000000e+00  2.97264113e-01 -3.48691665e-01  6.72064478e-03]\n",
      " [ 1.00000000e+00 -7.16288868e-01  8.46475352e-01  8.62912377e-01]\n",
      " [ 1.00000000e+00  4.82926468e-01 -3.48691665e-01 -2.28041604e-01]\n",
      " [ 1.00000000e+00  1.92172214e-01  9.13998912e-01 -1.06582061e+00]\n",
      " [ 1.00000000e+00 -3.48467222e-01 -5.78271770e-01 -1.15788424e+00]\n",
      " [ 1.00000000e+00  1.02123053e+00 -1.34128800e+00  2.49704176e+00]\n",
      " [ 1.00000000e+00 -1.50798117e+00  9.68017760e-01 -4.12168859e-01]\n",
      " [ 1.00000000e+00  6.97781017e-01 -1.21974559e+00 -5.13438849e-01]\n",
      " [ 1.00000000e+00  7.98202165e-01  2.26879163e-02  1.24497643e+00]\n",
      " [ 1.00000000e+00  1.60273904e+00 -8.55118367e-01 -1.11185242e+00]\n",
      " [ 1.00000000e+00 -1.13315340e+00 -7.87594807e-01 -5.59470662e-01]\n",
      " [ 1.00000000e+00  2.03849092e-01 -1.59625696e-01  7.75451931e-01]\n",
      " [ 1.00000000e+00 -1.48813048e+00 -2.13644545e-01 -6.23915201e-01]\n",
      " [ 1.00000000e+00  2.49388915e-01 -1.09145083e+00 -8.17248818e-01]\n",
      " [ 1.00000000e+00  8.79940308e-01 -1.34128800e+00 -8.03439274e-01]\n",
      " [ 1.00000000e+00  1.51633014e+00  1.73103399e+00  5.17673775e-01]\n",
      " [ 1.00000000e+00  1.18353913e+00  4.68343414e-01 -4.72010216e-01]\n",
      " [ 1.00000000e+00  2.70407294e-01 -1.04418434e+00  2.13863806e-01]\n",
      " [ 1.00000000e+00  1.51399477e+00 -1.41556392e+00 -3.15502050e-01]\n",
      " [ 1.00000000e+00  2.16693657e-01 -8.95632503e-01 -5.96296113e-01]\n",
      " [ 1.00000000e+00  1.11601758e-01 -1.39530685e+00 -1.02439198e+00]\n",
      " [ 1.00000000e+00  8.34400486e-01 -1.20624088e+00 -1.45184340e-01]\n",
      " [ 1.00000000e+00 -1.06075676e+00 -1.18598381e+00 -3.93111688e-02]\n",
      " [ 1.00000000e+00  1.64127273e+00  1.33264499e+00  1.89862818e+00]\n",
      " [ 1.00000000e+00  1.24659427e+00 -1.32616272e-01 -2.55016247e-02]\n",
      " [ 1.00000000e+00  6.76762637e-01  1.47444446e+00 -5.04232486e-01]\n",
      " [ 1.00000000e+00 -8.80728498e-02 -1.42906863e+00 -1.82009791e-01]\n",
      " [ 1.00000000e+00  5.14454038e-01  3.67058074e-01 -5.68677025e-01]\n",
      " [ 1.00000000e+00  1.62258973e+00 -6.32290618e-01 -1.23613832e+00]\n",
      " [ 1.00000000e+00 -1.49863967e+00 -7.53833027e-01 -3.29311594e-01]\n",
      " [ 1.00000000e+00 -1.25576062e+00  1.20435022e+00 -1.13947151e+00]\n",
      " [ 1.00000000e+00 -8.35393020e-01 -8.41613655e-01 -1.13026515e+00]\n",
      " [ 1.00000000e+00 -1.51615499e+00 -1.29402151e+00  4.81492770e-02]\n",
      " [ 1.00000000e+00  2.30705910e-01  1.26512143e+00 -1.24074150e+00]\n",
      " [ 1.00000000e+00  3.10313024e-02  8.32970639e-01 -1.13026515e+00]\n",
      " [ 1.00000000e+00 -1.27094056e+00 -1.32103093e+00 -7.71217005e-01]\n",
      " [ 1.00000000e+00 -6.17035408e-01 -1.24000266e+00 -1.03359834e+00]\n",
      " [ 1.00000000e+00  3.49810063e-01 -9.42898996e-01 -1.11185242e+00]\n",
      " [ 1.00000000e+00  1.59456522e+00  1.26512143e+00  1.64085003e+00]\n",
      " [ 1.00000000e+00  9.93206022e-01 -9.90165488e-01 -1.00597925e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.hstack((np.ones((len(X), 1)), X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return ((y_pred-y)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, np.median(y))\n",
    "print(np.round(answer1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.pinv(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0225      3.91925365  2.79206274 -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.942\n"
     ]
    }
   ],
   "source": [
    "x = np.mean(X, axis=0)\n",
    "\n",
    "answer2 = norm_eq_weights[0] + norm_eq_weights[1]*x[0] + norm_eq_weights[1]*x[1] + norm_eq_weights[2]*x[2]+norm_eq_weights[3]*x[3]\n",
    "print(round(answer2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(round(answer3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = X[train_ind][0]*(y[train_ind] - (w[3]+w[0]*X[train_ind][0] + w[1]*X[train_ind][1] + w[2]*X[train_ind][2]))\n",
    "    grad1 = X[train_ind][1]*(y[train_ind] - (w[3]+w[0]*X[train_ind][0] + w[1]*X[train_ind][1] + w[2]*X[train_ind][2]))\n",
    "    grad2 = X[train_ind][2]*(y[train_ind] - (w[3]+w[0]*X[train_ind][0] + w[1]*X[train_ind][1] + w[2]*X[train_ind][2]))\n",
    "    grad3 = (y[train_ind] - (w[3]+w[0]*X[train_ind][0] + w[1]*X[train_ind][1] + w[2]*X[train_ind][2]))\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- min_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        w_cur = stochastic_gradient_step(X, y, w, random_ind, eta=1e-2)\n",
    "        weight_dist = np.linalg.norm(w_cur-w, ord=2)\n",
    "        w= w_cur\n",
    "        err = mserror(y, linear_prediction(X, w))\n",
    "        errors.append(err)\n",
    "        iter_num+=1\n",
    "        \n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in square\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 53.3 ms, total: 1.69 s\n",
      "Wall time: 1.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_init = np.zeros(4)\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf,  inf, -inf, -inf])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1639749410333862e+200\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(round(answer4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
